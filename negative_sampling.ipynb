{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd0c0bba2e4c6e373ae0a6659ff5fed8ce7b58220f87173975cdd86d17e9aa5779a",
   "display_name": "Python 3.8.2 64-bit ('CRC_GNN': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## dataset 준비\n",
    "dataset을 negative item을 추가해서 준비한다.\n",
    "\n",
    "1. outfit을 구성하는 item의 갯수 중 50퍼센트가 넘지않게 item을 랜덤하게 선택한다.\n",
    "2. 해당 item과 같은 category의 다른 item을 negative item으로 대체한다.\n",
    "3. negative item이라 하면은 outfit의 나머지 item들과 다른 outfit에서도 함께 등장하지 않은 item을 뜻한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict     ### dictionary의 value에 list를 추가하고싶을 때 이 라이브러리를 쓰면됨\n",
    "from random import *\n",
    "import secrets\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "source": [
    "## Json data load\n",
    "\n",
    "train data는 17316개의 outfit으로 구성되어 있다.\n",
    "<br/>\n",
    "valid data는 1497개의 outfit으로 구성되어 있다.\n",
    "<br/>\n",
    "test data는 3076개의 outfit으로 구성되어 있다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_data shape: (17316,)\nvalid_data shape: (1497,)\ntest_data shape:  (3076,)\n"
     ]
    }
   ],
   "source": [
    "### json, image의 path\n",
    "json_path = './polyvore-dataset-master/'\n",
    "image_path = json_path + 'images/'\n",
    "\n",
    "### train, valid, testset의 json read\n",
    "with open(json_path + 'train_no_dup.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "with open(json_path + 'valid_no_dup.json', 'r') as f:\n",
    "    valid_data = json.load(f)\n",
    "\n",
    "with open(json_path + 'test_no_dup.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "### data 구조 확인\n",
    "print('train_data shape: {}'.format(np.shape(train_data)))\n",
    "print('valid_data shape: {}'.format(np.shape(valid_data)))\n",
    "print('test_data shape:  {}'.format(np.shape(test_data)))"
   ]
  },
  {
   "source": [
    "### Outfit을 구성하는 item의 갯수 중 50% 넘지 않게 item을 random하게 선택한다.\n",
    "\n",
    "* 각 item 별로 등장하는 outfit을 찾는다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "### item별로 등장하는 outfit을 찾는다.\n",
    "### defaultdict()를 사용하면 dictionary의 value에 list를 넣기 쉬움\n",
    "train_item2outfit = defaultdict(list)\n",
    "valid_item2outfit = defaultdict(list)\n",
    "test_item2outfit  = defaultdict(list)\n",
    "\n",
    "### train data\n",
    "for i in range(len(train_data)):\n",
    "    list_ids = []\n",
    "    ### 각 outfit에 있는 item들을 list에 저장한다.\n",
    "    for j in range(len(train_data[i]['items'])):\n",
    "        _, ids = train_data[i]['items'][j]['image'].split('id=')\n",
    "        list_ids.append(ids)\n",
    "    ### 저장한 list의 item이 등장하는 outfit을 붙인다.\n",
    "    for j in range(len(list_ids)):\n",
    "        train_item2outfit[list_ids[j]].append(train_data[i]['set_id'])\n",
    "\n",
    "### valid data\n",
    "for i in range(len(valid_data)):\n",
    "    list_ids = []\n",
    "    for j in range(len(valid_data[i]['items'])):\n",
    "        _, ids = valid_data[i]['items'][j]['image'].split('id=')\n",
    "        list_ids.append(ids)\n",
    "    for j in range(len(list_ids)):\n",
    "        valid_item2outfit[list_ids[j]].append(valid_data[i]['set_id'])\n",
    "\n",
    "### test data\n",
    "for i in range(len(test_data)):\n",
    "    list_ids = []\n",
    "    for j in range(len(test_data[i]['items'])):\n",
    "        _, ids = test_data[i]['items'][j]['image'].split('id=')\n",
    "        list_ids.append(ids)\n",
    "    for j in range(len(list_ids)):\n",
    "        test_item2outfit[list_ids[j]].append(test_data[i]['set_id'])\n"
   ]
  },
  {
   "source": [
    "data를 저장해서 확인해본다.\n",
    "<br/>\n",
    "key: item_id, value: outfit_list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './negative_outfit/'\n",
    "\n",
    "with open(save_path + 'train_item2outfit.json', 'w') as f:\n",
    "    json.dump(train_item2outfit, f, indent=4)\n",
    "\n",
    "with open(save_path + 'valid_item2outfit.json', 'w') as f:\n",
    "    json.dump(valid_item2outfit, f, indent=4)\n",
    "\n",
    "with open(save_path + 'test_item2outfit.json', 'w') as f:\n",
    "    json.dump(test_item2outfit, f, indent=4)"
   ]
  },
  {
   "source": [
    "outfit에 있는 item을 절반이 넘지 않게 랜덤하게 선택해본다.\n",
    "<br/>\n",
    "먼저 outfit 별로 갖고 있는 item을 확인할 수 있도록 간략하게 json file을 만들어본다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### outfit에 등장하는 item들을 저장한다.\n",
    "### defaultdict()를 사용하면 dictionary의 value에 list를 넣기 쉬움\n",
    "train_outfit2item = defaultdict(list)\n",
    "valid_outfit2item = defaultdict(list)\n",
    "test_outfit2item  = defaultdict(list)\n",
    "\n",
    "train_set_ids = []\n",
    "valid_set_ids = []\n",
    "test_set_ids  = []\n",
    "\n",
    "### train data\n",
    "for i in range(len(train_data)):\n",
    "    train_list_ids = []\n",
    "    set_id = train_data[i]['set_id']\n",
    "    train_set_ids.append(set_id)\n",
    "    for j in range(len(train_data[i]['items'])):\n",
    "        _, ids = train_data[i]['items'][j]['image'].split('id=')\n",
    "        train_list_ids.append(ids)\n",
    "\n",
    "    train_outfit2item[set_id] = train_list_ids\n",
    "\n",
    "### valid data\n",
    "for i in range(len(valid_data)):\n",
    "    valid_list_ids = []\n",
    "    set_id = valid_data[i]['set_id']\n",
    "    valid_set_ids.append(set_id)\n",
    "    for j in range(len(valid_data[i]['items'])):\n",
    "        _, ids = valid_data[i]['items'][j]['image'].split('id=')\n",
    "        valid_list_ids.append(ids)\n",
    "\n",
    "    valid_outfit2item[set_id] = valid_list_ids\n",
    "\n",
    "### test data\n",
    "for i in range(len(test_data)):\n",
    "    test_list_ids = []\n",
    "    set_id = test_data[i]['set_id']\n",
    "    test_set_ids.append(set_id)\n",
    "    for j in range(len(test_data[i]['items'])):\n",
    "        _, ids = test_data[i]['items'][j]['image'].split('id=')\n",
    "        test_list_ids.append(ids)\n",
    "\n",
    "    test_outfit2item[set_id] = test_list_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + 'train_outfit2item.json', 'w') as f:\n",
    "    json.dump(train_outfit2item, f, indent=4)\n",
    "\n",
    "with open(save_path + 'valid_outfit2item.json', 'w') as f:\n",
    "    json.dump(valid_outfit2item, f, indent=4)\n",
    "\n",
    "with open(save_path + 'test_outfit2item.json', 'w') as f:\n",
    "    json.dump(test_outfit2item, f, indent=4)"
   ]
  },
  {
   "source": [
    "outfit 내에서 item을 랜덤하게 50%가 넘지 않게 선택한다. <br/>\n",
    "이 때, 이 item을 대체할 item은 다른 outfit에서 한번도 같이 등장한 적이 없어야한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_choice_items = defaultdict(list)\n",
    "valid_choice_items = defaultdict(list)\n",
    "test_choice_items = defaultdict(list)\n",
    "\n",
    "### train data에 대하여\n",
    "for i in range(len(train_data)):\n",
    "    ### rand_num: 각 outfit 별로 random하게 선택할 item의 갯수\n",
    "    set_id = train_data[i]['set_id']\n",
    "    length = len(train_outfit2item[train_set_ids[i]])//2\n",
    "    rand_num = np.random.randint(1, length)\n",
    "    # print(rand_num)\n",
    "    \n",
    "    ### random한 item을 선택한다.\n",
    "    choice = random.choices(train_outfit2item[train_set_ids[i]], k=rand_num)\n",
    "    train_choice_items[set_id] = choice\n",
    "\n",
    "### valid data에 대하여\n",
    "for i in range(len(valid_data)):\n",
    "    set_id = valid_data[i]['set_id']\n",
    "    length = len(valid_outfit2item[valid_set_ids[i]])//2\n",
    "    rand_num = np.random.randint(1, length)\n",
    "\n",
    "    choice = random.choices(valid_outfit2item[valid_set_ids[i]], k=rand_num)\n",
    "    valid_choice_items[set_id] = choice\n",
    "\n",
    "### test data에 대하여\n",
    "for i in range(len(test_data)):\n",
    "    set_id = test_data[i]['set_id']\n",
    "    length = len(test_outfit2item[test_set_ids[i]])//2\n",
    "    rand_num = np.random.randint(1, length)\n",
    "\n",
    "    choice = random.choices(test_outfit2item[test_set_ids[i]], k=rand_num)\n",
    "    test_choice_items[set_id] = choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: outfit id, value: negative item으로 선택될 n개의 items\n",
    "with open(save_path + 'train_choice_item.json', 'w') as f:\n",
    "    json.dump(train_choice_items, f, indent=4)\n",
    "\n",
    "with open(save_path + 'valid_choice_item.json', 'w') as f:\n",
    "    json.dump(valid_choice_items, f, indent=4)\n",
    "\n",
    "with open(save_path + 'test_choice_item.json', 'w') as f:\n",
    "    json.dump(test_choice_items, f, indent=4)"
   ]
  },
  {
   "source": [
    "negative item의 후보로 선택된 item을 다른 item으로 넣어준다. <br/>\n",
    "이 때, 다른 item은 선택된 item과 같은 category여야한다. <br/>\n",
    "또한, 선택되지 않은 나머지 item들과 어떠한 outfit에서도 함께 등장하지 아니한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + 'train_choice_item.json', 'r') as f:\n",
    "    train_choice = json.load(f)\n",
    "    \n",
    "with open(save_path + 'valid_choice_item.json', 'r') as f:\n",
    "    valid_choice = json.load(f)\n",
    "\n",
    "with open(save_path + 'test_choice_item.json', 'r') as f:\n",
    "    test_choice = json.load(f)\n",
    "\n",
    "with open(save_path + 'all_item2outfit.json', 'r') as f:\n",
    "    item2outfit = json.load(f)\n",
    "\n",
    "with open(save_path + 'all_outfit2item.json', 'r') as f:\n",
    "    outfit2item = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_choice)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "생각해보니까 train, valid, test set에 중복되는 item들이 있음 <br/>\n",
    "그렇기 때문에 한번에 다 넣어서 찾아야함 <br/>\n",
    "하지만 dataset을 소개한 논문을 확인해본 결과, 중복되는 item은 없음"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # from itertools import chain\n",
    "# # from collections import defaultdict\n",
    "\n",
    "# # tmp_outfit2item = defaultdict(list)\n",
    "# # all_outfit2item = defaultdict(list)\n",
    "\n",
    "# # for k, v in chain(train_outfit2item.items(), valid_outfit2item.items()):\n",
    "# #     tmp_outfit2item[k].append(v)\n",
    "\n",
    "# # for k, v in chain(tmp_outfit2item.items(), test_outfit2item.items()):\n",
    "# #     all_outfit2item[k].append(v)\n",
    "\n",
    "# # tmp_item2outfit = defaultdict(list)\n",
    "# # all_item2outfit = defaultdict(list)\n",
    "\n",
    "# # for k, v in chain(train_item2outfit.items(), valid_item2outfit.items()):\n",
    "# #     tmp_item2outfit[k].append(v)\n",
    "\n",
    "# # for k, v in chain(tmp_item2outfit.items(), test_item2outfit.items()):\n",
    "# #     all_item2outfit[k].append(v)\n",
    "\n",
    "# train_outfit2item.update(valid_outfit2item)\n",
    "# train_outfit2item.update(test_outfit2item)\n",
    "\n",
    "# train_item2outfit.update(valid_item2outfit)\n",
    "# train_item2outfit.update(test_item2outfit)\n",
    "\n",
    "# all_outfit2item = train_outfit2item\n",
    "# all_item2outfit = train_item2outfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(save_path + 'all_outfit2item.json', 'w') as f:\n",
    "#     json.dump(all_outfit2item, f, indent=4)\n",
    "\n",
    "# with open(save_path + 'all_item2outfit.json', 'w') as f:\n",
    "#     json.dump(all_item2outfit, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}